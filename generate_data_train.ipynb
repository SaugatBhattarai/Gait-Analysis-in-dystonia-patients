{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from numpy.linalg import svd\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "# from procrustes import procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes(X, Y, scaling=True, reflection='best'):\n",
    "    \"\"\"\n",
    "    A port of MATLAB's `procrustes` function to Numpy.\n",
    "\n",
    "    Procrustes analysis determines a linear transformation (translation,\n",
    "    reflection, orthogonal rotation and scaling) of the points in Y to best\n",
    "    conform them to the points in matrix X, using the sum of squared errors\n",
    "    as the goodness of fit criterion.\n",
    "\n",
    "        d, Z, [tform] = procrustes(X, Y)\n",
    "\n",
    "    Inputs:\n",
    "    ------------\n",
    "    X, Y    \n",
    "        matrices of target and input coordinates. they must have equal\n",
    "        numbers of  points (rows), but Y may have fewer dimensions\n",
    "        (columns) than X.\n",
    "\n",
    "    scaling \n",
    "        if False, the scaling component of the transformation is forced\n",
    "        to 1\n",
    "\n",
    "    reflection\n",
    "        if 'best' (default), the transformation solution may or may not\n",
    "        include a reflection component, depending on which fits the data\n",
    "        best. setting reflection to True or False forces a solution with\n",
    "        reflection or no reflection respectively.\n",
    "\n",
    "    Outputs\n",
    "    ------------\n",
    "    d       \n",
    "        the residual sum of squared errors, normalized according to a\n",
    "        measure of the scale of X, ((X - X.mean(0))**2).sum()\n",
    "\n",
    "    Z\n",
    "        the matrix of transformed Y-values\n",
    "\n",
    "    tform   \n",
    "        a dict specifying the rotation, translation and scaling that\n",
    "        maps X --> Y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n,m = X.shape\n",
    "    ny,my = Y.shape\n",
    "\n",
    "    muX = X.mean(0)\n",
    "    muY = Y.mean(0)\n",
    "\n",
    "    X0 = X - muX\n",
    "    Y0 = Y - muY\n",
    "\n",
    "    ssX = (X0**2.).sum()\n",
    "    ssY = (Y0**2.).sum()\n",
    "\n",
    "    # centred Frobenius norm\n",
    "    normX = np.sqrt(ssX)\n",
    "    normY = np.sqrt(ssY)\n",
    "\n",
    "    # scale to equal (unit) norm\n",
    "    X0 /= normX\n",
    "    Y0 /= normY\n",
    "\n",
    "    if my < m:\n",
    "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
    "\n",
    "    # optimum rotation matrix of Y\n",
    "    A = np.dot(X0.T, Y0)\n",
    "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    T = np.dot(V, U.T)\n",
    "\n",
    "    if reflection is not 'best':\n",
    "\n",
    "        # does the current solution use a reflection?\n",
    "        have_reflection = np.linalg.det(T) < 0\n",
    "\n",
    "        # if that's not what was specified, force another reflection\n",
    "        if reflection != have_reflection:\n",
    "            V[:,-1] *= -1\n",
    "            s[-1] *= -1\n",
    "            T = np.dot(V, U.T)\n",
    "\n",
    "    traceTA = s.sum()\n",
    "\n",
    "    if scaling:\n",
    "\n",
    "        # optimum scaling of Y\n",
    "        b = traceTA * normX / normY\n",
    "\n",
    "        # standarised distance between X and b*Y*T + c\n",
    "        d = 1 - traceTA**2\n",
    "\n",
    "        # transformed coords\n",
    "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
    "\n",
    "    else:\n",
    "        b = 1\n",
    "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
    "        Z = normY*np.dot(Y0, T) + muX\n",
    "\n",
    "    # transformation matrix\n",
    "    if my < m:\n",
    "        T = T[:my,:]\n",
    "    c = muX - b*np.dot(muY, T)\n",
    "\n",
    "    #transformation values \n",
    "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
    "\n",
    "    return d, Z, tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_input(image):\n",
    "  processed = np.empty((0,51))\n",
    "  for frame in image:\n",
    "    intermediate = frame.flatten()\n",
    "    processed = np.append(processed,[intermediate],axis=0)\n",
    "  return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = 'datasets/train'\n",
    "datasets_folder_path = os.path.abspath(\"datasets/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_class = []\n",
    "for class_folder in os.listdir(datasets_folder):\n",
    "    for filename in os.listdir(datasets_folder_path+'/'+class_folder):\n",
    "        image_path = 'datasets/train/'+class_folder+'/'+filename\n",
    "        image_class.append({\"image\":image_path,\"class\":class_folder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['image','class']\n",
    "dict_data = image_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'dystonia_dataset_train.csv'\n",
    "try:\n",
    "    with open(csv_file,'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print('I/O error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(data):\n",
    "    normalized_data = np.empty((0,17,3))\n",
    "    reference_frame = data[0]\n",
    "\n",
    "    for frame in data:\n",
    "        d, Z, tform = procrustes(reference_frame, frame)\n",
    "        normalized_data = np.append(normalized_data,[Z],axis=0)\n",
    "#         print(normalized_data)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def default(obj):\n",
    "    if type(obj).__module__ == np.__name__:\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj.item()\n",
    "    raise TypeError('Unknown type:', type(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_class = []\n",
    "for class_folder in os.listdir(datasets_folder):\n",
    "    for filename in os.listdir(datasets_folder_path+'/'+class_folder):\n",
    "        image_path = datasets_folder_path+'/'+class_folder+'/'+filename\n",
    "        data  = np.load(image_path)\n",
    "        subsampled_data = data[::3]\n",
    "        normalized_data = data_normalization(subsampled_data)\n",
    "        flattened_data = flatten_input(normalized_data)\n",
    "        flattened_data = np.expand_dims(flattened_data, axis=2)\n",
    "        serialized_data = json.dumps(flattened_data, default=default)\n",
    "        image_class.append({\"image\":serialized_data,\"class\":class_folder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['image','class']\n",
    "dict_data = image_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'dystonia_dataset_train_normalized.csv'\n",
    "try:\n",
    "    with open(csv_file,'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print('I/O error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
